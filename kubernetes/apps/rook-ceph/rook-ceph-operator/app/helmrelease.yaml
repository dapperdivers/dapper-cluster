---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: rook-ceph-operator
spec:
  interval: 30m
  chart:
    spec:
      chart: rook-ceph
      version: v1.18.2
      sourceRef:
        kind: HelmRepository
        name: rook
        namespace: flux-system
  install:
    remediation:
      retries: 3
    createNamespace: true
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  values:
    crds:
      enabled: true

    # Override Ceph version to match external cluster (Reef 18.2.7)
    # Pinned to v18.x - must match Proxmox Ceph cluster version
    # renovate: datasource=docker depName=quay.io/ceph/ceph versioning=semver extractVersion=^v(?<version>.*)$ constraints=18.x
    cephVersion:
      image: quay.io/ceph/ceph:v18.2.7

    csi:
      # Phase 1: Only CephFS is available
      # Enable RBD driver for block storage (Phase 2 - after pool creation)
      enableRbdDriver: false
      # Enable CephFS driver for shared filesystem storage
      enableCephfsDriver: true

      # CSI driver resource configuration
      csiRBDProvisionerResource: |
        - name: csi-provisioner
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-resizer
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-attacher
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-snapshotter
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-rbdplugin
          resource:
            requests:
              memory: 512Mi
              cpu: 250m
            limits:
              memory: 1Gi
              cpu: 500m
        - name: liveness-prometheus
          resource:
            requests:
              memory: 128Mi
              cpu: 50m
            limits:
              memory: 256Mi
              cpu: 100m

      csiCephFSProvisionerResource: |
        - name: csi-provisioner
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-resizer
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-attacher
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-snapshotter
          resource:
            requests:
              memory: 128Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 200m
        - name: csi-cephfsplugin
          resource:
            requests:
              memory: 512Mi
              cpu: 250m
            limits:
              memory: 1Gi
              cpu: 500m
        - name: liveness-prometheus
          resource:
            requests:
              memory: 128Mi
              cpu: 50m
            limits:
              memory: 256Mi
              cpu: 100m

    # Enable monitoring
    monitoring:
      enabled: true

    # Operator resource configuration
    resources:
      limits:
        cpu: "1"
        memory: "512Mi"
      requests:
        cpu: "100m"
        memory: "128Mi"

    # Node selector for running on specific nodes (optional)
    # nodeSelector:
    #   node-role.kubernetes.io/worker: "true"

    # Toleration for taints (optional)
    # tolerations: []
