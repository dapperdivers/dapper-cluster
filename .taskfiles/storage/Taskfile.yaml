---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

# Taskfile for managing storage class migrations
# Primary use case: Migrating PVCs from mayastor-single-replica to cephfs-shared (and later to ceph-rbd)

vars:
  KUBECTL: kubectl

tasks:

  list-mayastor:
    desc: List all PVCs still using mayastor-single-replica storage class
    summary: |
      Shows which PVCs are still on mayastor storage to help track migration progress.
      Groups by namespace for easier planning.
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "PVCs using mayastor-single-replica storage class:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

        PVCS=$({{.KUBECTL}} get pvc -A -o json | jq -r '.items[] | select(.spec.storageClassName=="mayastor-single-replica") | "\(.metadata.namespace)/\(.metadata.name)"' | sort)

        if [ -z "$PVCS" ]; then
          echo "✅ No PVCs found using mayastor-single-replica!"
          echo "   All PVCs have been migrated off Mayastor."
        else
          COUNT=$(echo "$PVCS" | wc -l)
          echo "$PVCS" | awk -F/ '{print "  " $1 "/" $2}'
          echo ""
          echo "Total: $COUNT PVCs still on mayastor-single-replica"
          echo ""
          echo "Run: task storage:migrate-pvc APP=<app> NS=<namespace> STORAGE_CLASS=cephfs-shared"
        fi
        echo ""

  verify-volsync:
    desc: Check volsync backup status for all apps
    summary: |
      Lists all ReplicationSources and their last sync time.
      Use this to verify apps have recent backups before migrating.
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "Volsync Backup Status (ReplicationSources):"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""
        printf "%-20s %-25s %-25s %s\n" "NAMESPACE" "APP" "LAST SYNC" "STATUS"
        echo "────────────────────────────────────────────────────────────────────────────────────"

        {{.KUBECTL}} get replicationsources -A -o json | jq -r '.items[] |
          [.metadata.namespace, .metadata.name, (.status.lastSyncTime // "Never"), (.status.lastSyncDuration // "N/A")] |
          @tsv' | while IFS=$'\t' read -r ns name sync duration; do
          printf "%-20s %-25s %-25s %s\n" "$ns" "$name" "$sync" "$duration"
        done
        echo ""

  show-progress:
    desc: Show migration progress - apps migrated vs remaining
    summary: |
      Displays which apps have been migrated to cephfs-shared (have overrides in ks.yaml)
      and which are still using default (mayastor).
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "Storage Migration Progress:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

        MIGRATED=0
        PENDING=0

        echo "Apps with storage class override (migrated to cephfs-shared):"
        echo "────────────────────────────────────────────────────────────────"

        # Find all ks.yaml files with VOLSYNC_STORAGECLASS override
        for ks_file in kubernetes/apps/*/*/ks.yaml; do
          if [ -f "$ks_file" ]; then
            if grep -q "VOLSYNC_STORAGECLASS.*cephfs-shared" "$ks_file" 2>/dev/null; then
              app=$(basename $(dirname "$ks_file"))
              ns=$(basename $(dirname $(dirname "$ks_file")))
              echo "  ✅ $ns/$app"
              MIGRATED=$((MIGRATED + 1))
            fi
          fi
        done

        echo ""
        echo "Apps still using default storage class (pending migration):"
        echo "────────────────────────────────────────────────────────────────"

        # Find apps with volsync component but no override
        for ks_file in kubernetes/apps/*/*/ks.yaml; do
          if [ -f "$ks_file" ]; then
            # Check if uses volsync component and has VOLSYNC_CAPACITY
            if grep -q "VOLSYNC_CAPACITY" "$ks_file" 2>/dev/null; then
              # Check if doesn't have cephfs override
              if ! grep -q "VOLSYNC_STORAGECLASS.*cephfs-shared" "$ks_file" 2>/dev/null; then
                app=$(basename $(dirname "$ks_file"))
                ns=$(basename $(dirname $(dirname "$ks_file")))
                echo "  ⏳ $ns/$app"
                PENDING=$((PENDING + 1))
              fi
            fi
          fi
        done

        echo ""
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        TOTAL=$((MIGRATED + PENDING))
        PERCENT=0
        if [ $TOTAL -gt 0 ]; then
          PERCENT=$((MIGRATED * 100 / TOTAL))
        fi
        echo "Progress: $MIGRATED/$TOTAL apps migrated ($PERCENT%)"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

  migrate-pvc:
    desc: Migrate a single app's PVC to a new storage class [APP=required] [NS=required] [STORAGE_CLASS=cephfs-shared] [COMMIT=false]
    summary: |
      Migrates an app's PVC to a new storage class by:
      1. Validating prerequisites (app exists, has volsync backup, etc.)
      2. Adding storage class override to app's ks.yaml
      3. Optionally committing and pushing changes (set COMMIT=true)
      4. Scaling down the app
      5. Waiting for PVC deletion and recreation with volsync restore
      6. Scaling app back up
      7. Verifying migration succeeded

      Examples:
        Manual commit: task storage:migrate-pvc APP=bazarr NS=media STORAGE_CLASS=cephfs-shared
        Auto commit:   task storage:migrate-pvc APP=bazarr NS=media STORAGE_CLASS=cephfs-shared COMMIT=true
    vars:
      NS: '{{.NS | default "default"}}'
      STORAGE_CLASS: '{{.STORAGE_CLASS | default "cephfs-shared"}}'
      SNAPSHOT_CLASS: '{{.STORAGE_CLASS}}-snapshot'
      COMMIT: '{{.COMMIT | default "false"}}'
      KS_FILE: '{{.ROOT_DIR}}/kubernetes/apps/{{.NS}}/{{.APP}}/ks.yaml'
      CONTROLLER:
        sh: '{{.KUBECTL}} --namespace {{.NS}} get deployment {{.APP}} &>/dev/null && echo deployment || echo statefulset'
      ORIGINAL_REPLICAS:
        sh: '{{.KUBECTL}} --namespace {{.NS}} get {{.CONTROLLER}}/{{.APP}} -o jsonpath="{.spec.replicas}" 2>/dev/null || echo "1"'
    requires:
      vars: [APP, NS]
    preconditions:
      - sh: '[ -f "{{.KS_FILE}}" ]'
        msg: 'Kustomization file not found at {{.KS_FILE}}'
      - sh: '{{.KUBECTL}} --namespace {{.NS}} get {{.CONTROLLER}}/{{.APP}} &>/dev/null'
        msg: 'App {{.APP}} not found in namespace {{.NS}}'
      - sh: '{{.KUBECTL}} --namespace {{.NS}} get replicationsource {{.APP}} &>/dev/null'
        msg: 'No volsync ReplicationSource found for {{.APP}} - cannot safely migrate'
      - sh: '{{.KUBECTL}} get storageclass {{.STORAGE_CLASS}} &>/dev/null'
        msg: 'Storage class {{.STORAGE_CLASS}} does not exist'
    cmds:
      - task: _validate-backup
        vars: {APP: '{{.APP}}', NS: '{{.NS}}'}
      - task: _commit-or-wait
        vars: {APP: '{{.APP}}', NS: '{{.NS}}', STORAGE_CLASS: '{{.STORAGE_CLASS}}', SNAPSHOT_CLASS: '{{.SNAPSHOT_CLASS}}', KS_FILE: '{{.KS_FILE}}', COMMIT: '{{.COMMIT}}'}
      - task: _scale-down
        vars: {APP: '{{.APP}}', NS: '{{.NS}}', CONTROLLER: '{{.CONTROLLER}}'}
      - task: _wait-for-pvc-recreation
        vars: {APP: '{{.APP}}', NS: '{{.NS}}', STORAGE_CLASS: '{{.STORAGE_CLASS}}'}
      - task: _scale-up
        vars: {APP: '{{.APP}}', NS: '{{.NS}}', CONTROLLER: '{{.CONTROLLER}}', REPLICAS: '{{.ORIGINAL_REPLICAS}}'}
      - task: _verify-migration
        vars: {APP: '{{.APP}}', NS: '{{.NS}}', STORAGE_CLASS: '{{.STORAGE_CLASS}}'}
      - echo "✅ Migration complete for {{.APP}}"

  # Internal task: Validate backup exists and is recent
  _validate-backup:
    internal: true
    vars:
      LAST_SYNC:
        sh: '{{.KUBECTL}} --namespace {{.NS}} get replicationsource {{.APP}} -o jsonpath="{.status.lastSyncTime}" 2>/dev/null || echo ""'
    cmds:
      - |
        if [ -z "{{.LAST_SYNC}}" ]; then
          echo "❌ No recent backup found for {{.APP}}"
          echo "   Run: task volsync:snapshot APP={{.APP}} NS={{.NS}}"
          exit 1
        fi
        echo "✅ Recent backup found: {{.LAST_SYNC}}"

  # Internal task: Add storage overrides and optionally commit
  _commit-or-wait:
    internal: true
    cmds:
      - |
        echo ""
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "📝 Updating Kustomization with storage class overrides"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

        # Check if yq is available
        if ! command -v yq &>/dev/null; then
          echo "❌ yq not found. Please install yq to use this task."
          echo "   Or manually edit {{.KS_FILE}} and add:"
          echo ""
          echo "  spec:"
          echo "    postBuild:"
          echo "      substitute:"
          echo "        VOLSYNC_STORAGECLASS: {{.STORAGE_CLASS}}"
          echo "        VOLSYNC_SNAPSHOTCLASS: {{.SNAPSHOT_CLASS}}"
          echo "        VOLSYNC_CACHE_STORAGECLASS: {{.STORAGE_CLASS}}"
          exit 1
        fi

        # Add storage class overrides using yq
        echo "   Adding VOLSYNC_STORAGECLASS: {{.STORAGE_CLASS}}"
        yq eval '.spec.postBuild.substitute.VOLSYNC_STORAGECLASS = "{{.STORAGE_CLASS}}"' -i {{.KS_FILE}}

        echo "   Adding VOLSYNC_SNAPSHOTCLASS: {{.SNAPSHOT_CLASS}}"
        yq eval '.spec.postBuild.substitute.VOLSYNC_SNAPSHOTCLASS = "{{.SNAPSHOT_CLASS}}"' -i {{.KS_FILE}}

        echo "   Adding VOLSYNC_CACHE_STORAGECLASS: {{.STORAGE_CLASS}}"
        yq eval '.spec.postBuild.substitute.VOLSYNC_CACHE_STORAGECLASS = "{{.STORAGE_CLASS}}"' -i {{.KS_FILE}}

        echo "✅ Updated {{.KS_FILE}}"
        echo ""

        if [ "{{.COMMIT}}" = "true" ]; then
          echo "🚀 Auto-commit enabled - committing and pushing changes..."
          echo ""

          # Stage the file
          git add {{.KS_FILE}}

          # Create commit message
          COMMIT_MSG="chore({{.NS}}): migrate {{.APP}} PVC to {{.STORAGE_CLASS}}

Storage class migration for {{.APP}}:
- VOLSYNC_STORAGECLASS: {{.STORAGE_CLASS}}
- VOLSYNC_SNAPSHOTCLASS: {{.SNAPSHOT_CLASS}}
- VOLSYNC_CACHE_STORAGECLASS: {{.STORAGE_CLASS}}

Part of mayastor to ceph migration."

          # Commit
          git commit -m "$COMMIT_MSG"

          # Push
          git push

          echo "✅ Changes committed and pushed"
          echo ""

          # Give Flux time to detect changes
          echo "🔄 Waiting for Flux to detect changes..."
          sleep 10

          # Trigger immediate reconciliation
          echo "   Triggering immediate Flux reconciliation..."
          flux reconcile source git flux-system --timeout 2m || true
          flux reconcile kustomization {{.APP}} --timeout 2m || true

          echo "✅ Flux reconciliation triggered"
        else
          echo "📋 Manual commit mode - changes have been made to {{.KS_FILE}}"
          echo ""
          echo "   Review the changes with: git diff {{.KS_FILE}}"
          echo ""
          echo "   When ready, commit and push:"
          echo "   git add {{.KS_FILE}}"
          echo "   git commit -m 'chore({{.NS}}): migrate {{.APP}} PVC to {{.STORAGE_CLASS}}'"
          echo "   git push"
          echo ""

          read -p "Press ENTER once you've committed and pushed, or Ctrl+C to abort: "
          echo ""

          echo "🔄 Waiting for Flux to reconcile the changes..."
          sleep 10

          echo "   Triggering immediate Flux reconciliation..."
          flux reconcile source git flux-system --timeout 2m || true
          flux reconcile kustomization {{.APP}} --timeout 2m || true

          echo "✅ Ready to proceed with migration"
        fi
        echo ""

  # Internal task: Scale down app
  _scale-down:
    internal: true
    cmds:
      - |
        echo "⏸️  Scaling down {{.APP}}..."
        {{.KUBECTL}} --namespace {{.NS}} scale {{.CONTROLLER}}/{{.APP}} --replicas=0
        echo "   Waiting for pods to terminate..."
        {{.KUBECTL}} --namespace {{.NS}} wait pod --for=delete --selector="app.kubernetes.io/name={{.APP}}" --timeout=5m || true
        echo "✅ App scaled down"

  # Internal task: Wait for PVC recreation
  _wait-for-pvc-recreation:
    internal: true
    cmds:
      - |
        echo "🔄 Triggering volsync restore with new storage class..."
        # Patch ReplicationDestination to trigger new restore with updated config
        {{.KUBECTL}} patch replicationdestination {{.APP}}-dst -n {{.NS}} --type merge -p "{\"spec\":{\"trigger\":{\"manual\":\"$(date +%s)\"}}}"

        echo "   Waiting for volsync restore job to start..."
        until {{.KUBECTL}} get job -n {{.NS}} 2>/dev/null | grep "volsync-dst-{{.APP}}-dst" &>/dev/null; do
          sleep 3
        done
        echo "   ✅ Restore job started"

        echo "   Waiting for restore job to complete..."
        # Wait for job with timeout, ignore if it completes quickly
        sleep 10

        echo "   Waiting for new snapshot to be created..."
        # Get the new snapshot name from ReplicationDestination status
        for i in {1..60}; do
          NEW_SNAPSHOT=$({{.KUBECTL}} get replicationdestination {{.APP}}-dst -n {{.NS}} -o jsonpath='{.status.latestImage.name}' 2>/dev/null)
          if [ -n "$NEW_SNAPSHOT" ]; then
            # Check if snapshot is ready
            SNAPSHOT_READY=$({{.KUBECTL}} get volumesnapshot "$NEW_SNAPSHOT" -n {{.NS}} -o jsonpath='{.status.readyToUse}' 2>/dev/null)
            if [ "$SNAPSHOT_READY" = "true" ]; then
              echo "   ✅ New snapshot ready: $NEW_SNAPSHOT"
              break
            fi
          fi
          sleep 5
        done

        echo "🗑️  Deleting volume snapshots that block PVC deletion..."
        # Delete snapshots that reference the PVC (they have finalizers preventing deletion)
        {{.KUBECTL}} get volumesnapshot -n {{.NS}} -o json | \
          jq -r ".items[] | select(.spec.source.persistentVolumeClaimName==\"{{.APP}}\") | .metadata.name" | \
          xargs -r {{.KUBECTL}} delete volumesnapshot -n {{.NS}} || true

        echo "🔄 Deleting old PVC (spec is immutable)..."
        {{.KUBECTL}} --namespace {{.NS}} delete pvc {{.APP}} --wait=false

        echo "   Waiting for old PVC to be fully deleted..."
        for i in {1..30}; do
          if ! {{.KUBECTL}} --namespace {{.NS}} get pvc {{.APP}} &>/dev/null; then
            echo "   ✅ Old PVC deleted"
            break
          fi
          sleep 5
        done

        echo "🔄 Triggering Flux reconciliation to recreate PVC..."
        flux --namespace {{.NS}} reconcile kustomization {{.APP}} --with-source

        echo "   Waiting for new PVC to be created..."
        until {{.KUBECTL}} --namespace {{.NS}} get pvc {{.APP}} &>/dev/null; do
          sleep 3
        done

        echo "   Waiting for PVC to be Bound (volsync restoring from backup)..."
        {{.KUBECTL}} --namespace {{.NS}} wait pvc/{{.APP}} --for=jsonpath='{.status.phase}'=Bound --timeout=10m

        # Verify storage class
        ACTUAL_SC=$({{.KUBECTL}} --namespace {{.NS}} get pvc {{.APP}} -o jsonpath='{.spec.storageClassName}')
        if [ "$ACTUAL_SC" != "{{.STORAGE_CLASS}}" ]; then
          echo "❌ PVC created with wrong storage class: $ACTUAL_SC (expected {{.STORAGE_CLASS}})"
          exit 1
        fi

        echo "✅ PVC recreated with storage class: {{.STORAGE_CLASS}}"

  # Internal task: Scale up app
  _scale-up:
    internal: true
    cmds:
      - |
        echo "▶️  Scaling up {{.APP}} to {{.REPLICAS}} replicas..."
        {{.KUBECTL}} --namespace {{.NS}} scale {{.CONTROLLER}}/{{.APP}} --replicas={{.REPLICAS}}
        echo "   Waiting for pods to be ready..."
        {{.KUBECTL}} --namespace {{.NS}} wait pod --for=condition=ready --selector="app.kubernetes.io/name={{.APP}}" --timeout=10m
        echo "✅ App scaled up and running"

  # Internal task: Verify migration
  _verify-migration:
    internal: true
    cmds:
      - |
        echo "🔍 Verifying migration..."

        # Check PVC storage class
        ACTUAL_SC=$({{.KUBECTL}} --namespace {{.NS}} get pvc {{.APP}} -o jsonpath='{.spec.storageClassName}')
        echo "   PVC storage class: $ACTUAL_SC"

        # Check pod status
        POD_STATUS=$({{.KUBECTL}} --namespace {{.NS}} get pods -l app.kubernetes.io/name={{.APP}} -o jsonpath='{.items[0].status.phase}')
        echo "   Pod status: $POD_STATUS"

        if [ "$ACTUAL_SC" = "{{.STORAGE_CLASS}}" ] && [ "$POD_STATUS" = "Running" ]; then
          echo "✅ Migration verified successfully"
        else
          echo "⚠️  Migration may have issues - please check manually"
        fi
