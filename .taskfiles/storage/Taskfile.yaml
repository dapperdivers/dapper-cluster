---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

# Taskfile for managing storage class migrations
# Current focus: Migrating apps from CephFS to RBD for better performance

vars:
  KUBECTL: kubectl

tasks:

  list-mayastor:
    desc: List all PVCs still using mayastor storage classes
    summary: |
      Shows which PVCs are still on mayastor/openebs storage.
      Used to track progress of Mayastor decommission.
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "PVCs using Mayastor/OpenEBS storage classes:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

        PVCS=$({{.KUBECTL}} get pvc -A -o json | jq -r '.items[] | select(.spec.storageClassName | test("mayastor|openebs")) | "\(.metadata.namespace)/\(.metadata.name) (\(.spec.storageClassName))"' | sort)

        if [ -z "$PVCS" ]; then
          echo "✅ No PVCs found using Mayastor/OpenEBS storage!"
          echo "   All PVCs have been migrated."
        else
          COUNT=$(echo "$PVCS" | wc -l)
          echo "$PVCS" | awk '{print "  " $0}'
          echo ""
          echo "Total: $COUNT PVCs remaining"
        fi
        echo ""

  verify-volsync:
    desc: Check volsync backup status for all apps
    summary: |
      Lists all ReplicationSources and their last sync time.
      Use this to verify apps have recent backups before migrating.
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "Volsync Backup Status (ReplicationSources):"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""
        printf "%-20s %-25s %-25s %s\n" "NAMESPACE" "APP" "LAST SYNC" "STATUS"
        echo "────────────────────────────────────────────────────────────────────────────────────"

        {{.KUBECTL}} get replicationsources -A -o json | jq -r '.items[] |
          [.metadata.namespace, .metadata.name, (.status.lastSyncTime // "Never"), (.status.lastSyncDuration // "N/A")] |
          @tsv' | while IFS=$'\t' read -r ns name sync duration; do
          printf "%-20s %-25s %-25s %s\n" "$ns" "$name" "$sync" "$duration"
        done
        echo ""

  show-progress:
    desc: Show migration progress - apps by storage class
    summary: |
      Displays which apps are on which storage classes.
      Helps track CephFS → RBD migration progress.
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "Storage Class Migration Progress:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

        RBD=0
        CEPHFS=0
        DEFAULT=0

        echo "Apps using ceph-rbd (migrated):"
        echo "────────────────────────────────────────────────────────────────"

        for ks_file in kubernetes/apps/*/*/ks.yaml; do
          if [ -f "$ks_file" ]; then
            if grep -q "VOLSYNC_STORAGECLASS.*ceph-rbd" "$ks_file" 2>/dev/null; then
              app=$(basename $(dirname "$ks_file"))
              ns=$(basename $(dirname $(dirname "$ks_file")))
              echo "  ✅ $ns/$app"
              RBD=$((RBD + 1))
            fi
          fi
        done

        echo ""
        echo "Apps using cephfs-shared:"
        echo "────────────────────────────────────────────────────────────────"

        for ks_file in kubernetes/apps/*/*/ks.yaml; do
          if [ -f "$ks_file" ]; then
            if grep -q "VOLSYNC_STORAGECLASS.*cephfs-shared" "$ks_file" 2>/dev/null; then
              app=$(basename $(dirname "$ks_file"))
              ns=$(basename $(dirname $(dirname "$ks_file")))
              echo "  📁 $ns/$app"
              CEPHFS=$((CEPHFS + 1))
            fi
          fi
        done

        echo ""
        echo "Apps using default storage class (cephfs-shared):"
        echo "────────────────────────────────────────────────────────────────"

        for ks_file in kubernetes/apps/*/*/ks.yaml; do
          if [ -f "$ks_file" ]; then
            if grep -q "VOLSYNC_CAPACITY" "$ks_file" 2>/dev/null; then
              if ! grep -q "VOLSYNC_STORAGECLASS" "$ks_file" 2>/dev/null; then
                app=$(basename $(dirname "$ks_file"))
                ns=$(basename $(dirname $(dirname "$ks_file")))
                echo "  ⏳ $ns/$app"
                DEFAULT=$((DEFAULT + 1))
              fi
            fi
          fi
        done

        echo ""
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        TOTAL=$((RBD + CEPHFS + DEFAULT))
        echo "Summary:"
        echo "  RBD: $RBD apps"
        echo "  CephFS (explicit): $CEPHFS apps"
        echo "  CephFS (default): $DEFAULT apps"
        echo "  Total: $TOTAL apps with volsync"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

  migrate-to-rbd:
    desc: Migrate an app from CephFS to RBD using volsync backup/restore [APP=required] [NS=required] [NONINTERACTIVE=false]
    summary: |
      Migrates an app to ceph-rbd storage class using volsync backup/restore.
      This is the recommended approach for apps with volsync configured.

      Prerequisites:
      - App must have volsync configured and recent backup
      - App should be single-pod or use ReadWriteOnce access

      Process:
      1. Verify volsync backup exists
      2. Scale down app
      3. Delete old PVC
      4. Update ks.yaml with RBD config (3 lines)
      5. Commit changes (interactive or auto with NONINTERACTIVE=true)
      6. Reconcile Flux (volsync auto-restores)
      7. Verify app is healthy

      Examples:
        # Interactive mode (default - asks before commit)
        task storage:migrate-to-rbd APP=actual NS=selfhosted

        # Non-interactive mode (auto-commits)
        task storage:migrate-to-rbd APP=searxng NS=selfhosted NONINTERACTIVE=true
        task storage:migrate-to-rbd APP=esphome NS=home-automation NONINTERACTIVE=true
    vars:
      KS_FILE: '{{.ROOT_DIR}}/kubernetes/apps/{{.NS}}/{{.APP}}/ks.yaml'
      NONINTERACTIVE: '{{.NONINTERACTIVE | default "false"}}'
      CONTROLLER:
        sh: '{{.KUBECTL}} --namespace {{.NS}} get deployment {{.APP}} &>/dev/null && echo deployment || ({{.KUBECTL}} --namespace {{.NS}} get statefulset {{.APP}} &>/dev/null && echo statefulset || echo unknown)'
    requires:
      vars: [APP, NS]
    preconditions:
      - sh: '[ -f "{{.KS_FILE}}" ]'
        msg: 'Kustomization file not found at {{.KS_FILE}}'
      - sh: '{{.KUBECTL}} --namespace {{.NS}} get {{.CONTROLLER}}/{{.APP}} &>/dev/null'
        msg: 'App {{.APP}} not found in namespace {{.NS}}'
      - sh: '{{.KUBECTL}} --namespace {{.NS}} get pvc {{.APP}} &>/dev/null'
        msg: 'PVC {{.APP}} not found in namespace {{.NS}}'
      - sh: '{{.KUBECTL}} --namespace {{.NS}} get replicationsource {{.APP}} &>/dev/null'
        msg: 'No volsync backup found for {{.APP}}. App must have volsync configured.'
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "Migrating {{.NS}}/{{.APP}} to ceph-rbd storage"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

        # Step 1: Verify backup
        echo "1. Verifying volsync backup..."
        LAST_SYNC=$({{.KUBECTL}} get replicationsource {{.APP}} -n {{.NS}} -o jsonpath='{.status.lastSyncTime}')
        if [ -z "$LAST_SYNC" ]; then
          echo "   ❌ No recent backup found!"
          exit 1
        fi
        echo "   ✅ Last backup: $LAST_SYNC"
        echo ""

        # Step 2: Show current state
        echo "2. Current PVC state:"
        CURRENT_SC=$({{.KUBECTL}} get pvc {{.APP}} -n {{.NS}} -o jsonpath='{.spec.storageClassName}')
        CURRENT_AM=$({{.KUBECTL}} get pvc {{.APP}} -n {{.NS}} -o jsonpath='{.spec.accessModes[0]}')
        SIZE=$({{.KUBECTL}} get pvc {{.APP}} -n {{.NS}} -o jsonpath='{.spec.resources.requests.storage}')
        echo "   Storage Class: $CURRENT_SC → ceph-rbd"
        echo "   Access Mode: $CURRENT_AM → ReadWriteOnce"
        echo "   Size: $SIZE"
        echo ""

        # Step 3: Scale down
        echo "3. Scaling down {{.APP}}..."
        {{.KUBECTL}} --namespace {{.NS}} scale {{.CONTROLLER}}/{{.APP}} --replicas=0
        echo "   Waiting for pods to terminate..."
        {{.KUBECTL}} --namespace {{.NS}} wait pod --for=delete --selector="app.kubernetes.io/name={{.APP}}" --timeout=5m 2>/dev/null || true
        echo "   ✅ App scaled down"
        echo ""

        # Step 4: Delete PVC
        echo "4. Deleting old PVC..."
        {{.KUBECTL}} delete pvc {{.APP}} -n {{.NS}}
        sleep 3
        echo "   ✅ PVC deleted"
        echo ""

        # Step 5: Update ks.yaml
        echo "5. Updating ks.yaml with RBD configuration..."

        # Check if postBuild.substitute exists
        if ! grep -q "postBuild:" {{.KS_FILE}}; then
          echo "   ❌ No postBuild section found in ks.yaml"
          exit 1
        fi

        # Add RBD config if not already present
        if ! grep -q "VOLSYNC_STORAGECLASS" {{.KS_FILE}}; then
          # Add after the last substitute line
          sed -i '/substitute:/a\      VOLSYNC_STORAGECLASS: ceph-rbd\n      VOLSYNC_SNAPSHOTCLASS: ceph-rbd-snapshot\n      VOLSYNC_ACCESSMODES: ReadWriteOnce' {{.KS_FILE}}
          echo "   ✅ Added RBD configuration"
        else
          # Update existing config
          sed -i 's/VOLSYNC_STORAGECLASS:.*/VOLSYNC_STORAGECLASS: ceph-rbd/' {{.KS_FILE}}
          sed -i 's/VOLSYNC_SNAPSHOTCLASS:.*/VOLSYNC_SNAPSHOTCLASS: ceph-rbd-snapshot/' {{.KS_FILE}}
          sed -i 's/VOLSYNC_ACCESSMODES:.*/VOLSYNC_ACCESSMODES: ReadWriteOnce/' {{.KS_FILE}}
          echo "   ✅ Updated RBD configuration"
        fi
        echo ""

        # Step 6: Show diff and commit
        echo "6. Changes to commit:"
        git diff {{.KS_FILE}} | grep "^[+-]" | grep -v "^[+-][+-][+-]"
        echo ""

        if [ "{{.NONINTERACTIVE}}" = "true" ]; then
          echo "Auto-committing (non-interactive mode)..."
          git add {{.KS_FILE}}
          git commit -m "feat({{.NS}}/{{.APP}}): migrate to ceph-rbd storage" \
            -m "Migrated from $CURRENT_SC to ceph-rbd for better performance." \
            -m "Volsync will auto-restore data from latest backup." \
            -m "🤖 Generated with Claude Code"
          git push
          echo "   ✅ Changes committed and pushed"
        else
          read -p "Commit these changes? (Y/n): " REPLY
          if [[ ! $REPLY =~ ^[Nn]$ ]]; then
            git add {{.KS_FILE}}
            git commit -m "feat({{.NS}}/{{.APP}}): migrate to ceph-rbd storage" \
              -m "Migrated from $CURRENT_SC to ceph-rbd for better performance." \
              -m "Volsync will auto-restore data from latest backup." \
              -m "🤖 Generated with Claude Code"
            git push
            echo "   ✅ Changes committed and pushed"
          else
            echo "   ⚠️  Skipping commit - you'll need to commit manually"
          fi
        fi
        echo ""

        # Step 7: Reconcile Flux
        echo "7. Reconciling Flux..."
        flux reconcile kustomization {{.APP}} -n {{.NS}} --with-source
        echo "   ✅ Flux reconciled"
        echo ""

        # Step 8: Wait for restoration
        echo "8. Waiting for volsync restoration..."
        echo "   This may take 30-60 seconds..."
        sleep 10

        for i in {1..12}; do
          if {{.KUBECTL}} get pvc {{.APP}} -n {{.NS}} &>/dev/null; then
            STATUS=$({{.KUBECTL}} get pvc {{.APP}} -n {{.NS}} -o jsonpath='{.status.phase}')
            if [ "$STATUS" = "Bound" ]; then
              echo "   ✅ PVC restored and bound"
              break
            fi
          fi
          echo "   ⏳ Waiting for PVC... ($i/12)"
          sleep 5
        done
        echo ""

        # Step 9: Wait for pod
        echo "9. Waiting for pod to be ready..."
        {{.KUBECTL}} --namespace {{.NS}} wait pod --for=condition=ready --selector="app.kubernetes.io/name={{.APP}}" --timeout=10m
        echo "   ✅ Pod is running"
        echo ""

        # Step 10: Verify
        echo "10. Verification:"
        NEW_SC=$({{.KUBECTL}} get pvc {{.APP}} -n {{.NS}} -o jsonpath='{.spec.storageClassName}')
        NEW_AM=$({{.KUBECTL}} get pvc {{.APP}} -n {{.NS}} -o jsonpath='{.spec.accessModes[0]}')
        echo "   Storage Class: $NEW_SC ✅"
        echo "   Access Mode: $NEW_AM ✅"

        POD_STATUS=$({{.KUBECTL}} get pods -n {{.NS}} -l app.kubernetes.io/name={{.APP}} -o jsonpath='{.items[0].status.phase}')
        echo "   Pod Status: $POD_STATUS ✅"
        echo ""

        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "✅ Migration complete for {{.NS}}/{{.APP}}"
        echo ""
        echo "Next steps:"
        echo "  - Check app logs: kubectl logs -n {{.NS}} -l app.kubernetes.io/name={{.APP}}"
        echo "  - Verify functionality in the app UI"
        echo "  - Monitor for a few hours to ensure stability"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

  list-rbd-candidates:
    desc: List apps that are good candidates for RBD migration
    summary: |
      Identifies apps currently on CephFS that could benefit from RBD.
      Checks for:
      - Apps using cephfs-shared storage
      - Apps with volsync backup configured
      - Single-pod deployments (good RWO candidates)
    cmds:
      - |
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "RBD Migration Candidates:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo ""

        echo "Apps with volsync on CephFS (ready to migrate):"
        echo "────────────────────────────────────────────────────────────────"

        for ks_file in kubernetes/apps/*/*/ks.yaml; do
          if [ -f "$ks_file" ]; then
            # Has volsync capacity and NOT already on RBD
            if grep -q "VOLSYNC_CAPACITY" "$ks_file" 2>/dev/null; then
              if ! grep -q "VOLSYNC_STORAGECLASS.*ceph-rbd" "$ks_file" 2>/dev/null; then
                app=$(basename $(dirname "$ks_file"))
                ns=$(basename $(dirname $(dirname "$ks_file")))

                # Check if PVC exists and is on CephFS
                if {{.KUBECTL}} get pvc "$app" -n "$ns" &>/dev/null; then
                  SC=$({{.KUBECTL}} get pvc "$app" -n "$ns" -o jsonpath='{.spec.storageClassName}')
                  SIZE=$({{.KUBECTL}} get pvc "$app" -n "$ns" -o jsonpath='{.spec.resources.requests.storage}')
                  AM=$({{.KUBECTL}} get pvc "$app" -n "$ns" -o jsonpath='{.spec.accessModes[0]}')

                  if [[ "$SC" == "cephfs-shared" ]]; then
                    # Check replica count
                    REPLICAS="?"
                    if {{.KUBECTL}} get deployment "$app" -n "$ns" &>/dev/null; then
                      REPLICAS=$({{.KUBECTL}} get deployment "$app" -n "$ns" -o jsonpath='{.spec.replicas}')
                    elif {{.KUBECTL}} get statefulset "$app" -n "$ns" &>/dev/null; then
                      REPLICAS=$({{.KUBECTL}} get statefulset "$app" -n "$ns" -o jsonpath='{.spec.replicas}')
                    fi

                    if [ "$REPLICAS" = "1" ]; then
                      echo "  ✅ $ns/$app ($SIZE, $AM, $REPLICAS replica)"
                    else
                      echo "  ⚠️  $ns/$app ($SIZE, $AM, $REPLICAS replicas - verify RWO compatibility)"
                    fi
                  fi
                fi
              fi
            fi
          fi
        done

        echo ""
        echo "To migrate an app:"
        echo "  task storage:migrate-to-rbd APP=<app> NS=<namespace>"
        echo ""
